## VMWare Fault Tolerance 原文翻译


# The Design of a Practical System for Fault-Tolerant Virtual Machines
这一篇文章介绍了当前唯一一个 VM 热备份的产品原理。包括：
* 如何保证主备 VM 同步（强一致性如何保证）；
* 主备间如何切换，以及如何保证只有一个 VM 对外提供服务等。

## Abstract

实现了一个商业企业级系统，提供容错虚拟机，其方法是通过另一台服务器上的备份虚拟机来复制主虚拟机的执行。

VMware vSphere 4.0 实现设计了一个完整的系统，该系统易于使用，可在商用服务器上运行，而且增加该功能后虚拟机性能下降不超过 10%。

此外，在几个实际应用中，保持主虚拟机和辅助虚拟机同步执行所需的数据带宽低于 20 Mbit/s，这使得在更远的距离上实现容错成为可能。

一个易于使用的商业系统，在故障后自动恢复冗余，除了复制的虚拟机执行，还需要许多额外的组件。我们设计并实现了这些额外的组件，并解决了在支持运行企业应用程序的 VM 时遇到的许多实际问题。

本文我们描述了基本设计，讨论了备选的设计选择和一些实现细节。

## 1. Introduction

实现容错服务器的常见方法是：主备份方法，如果主服务器发生故障，备份服务器可以接管。

复制备份服务器上的状态的一种方法是将主服务器的所有状态的变化，包括CPU、内存和I/O设备的变化，几乎连续地传送到备份服务器上。然而，发送这种状态所需的带宽，特别是内存的变化，可能非常大。

**虚拟机 state-machine approach**

状态机方法能够减少带宽：将服务器建模为确定性状态机，通过从相同的初始状态启动它们并确保它们以相同的顺序接收相同的输入请求来保持同步。

由于大多数服务器或服务都有一些不确定的操作，所以必须使用额外的 coordination 来确保主用和备用保持同步。然而，保持主备同步所需的额外信息量远远小于主备中正在变化的状态（主要是内存更新）量。

随着处理器频率的提高，在物理服务器上保证 coordination 是困难的。相比之下，在管理程序之上运行的虚拟机（VM）是实现状态机方法的绝佳平台。

一个虚拟机可以被认为是一个定义明确的状态机，其操作是被虚拟的机器（包括其所有设备）的操作。**与物理服务器一样，虚拟机有一些非确定性的操作（例如，读取时间的时钟或交付中断），因此必须向备份发送额外的信息，以确保其保持同步。**由于 hypervisor 完全控制了虚拟机的执行，包括所有输入的交付， hypervisor 能够捕捉到所有关于主虚拟机上的非确定性操作的必要信息，并在备份虚拟机上正确重放这些操作。

此外，状态机方法所需的低带宽允许主机和备份机有更大的物理间隔。例如，备份的虚拟机可以在分布在校园内的物理机上运行，这比在同一建筑物内运行的虚拟机更可靠。

本文组织：

1. 介绍基本设计和细节，确保在主 VM 失效后，备 VM 能够立刻接管，期间没有数据丢失；
2. 描述一些重要问题的细节，以建立一个高效完全自动化的系统；
3. 描述一些实现 FT VM 的设计选择，并讨论这样设计的权衡；
4. 给出实现结果、相关工作、总结。

## 2. BASIC FT DESIGN

FT VM 的基本设置如下图所示。

![FTVM-setup.png](https://cdn.hashnode.com/res/hashnode/image/upload/v1651655983043/iGprJPIhY.png align="left")

| 相关概念          | 解释                                                         |
| ----------------- | ------------------------------------------------------------ |
| primary VM        | 主服务器                                                     |
| backup VM         | 备份服务器，与主服务器不在同一个物理服务器上                 |
| virtual lock-step | 主服务器和备份服务器同步并执行相同的程序，备份服务器有一定的时间延迟 |
| Shared Disk       | Fibre Channel / iSCSI disk array                             |
| Logging channel   | 所有主 VM 接收到的 inputs 通过该 channel 的网络连接传到备份 VM 上 |

对于传输的数据，主要的工作量在于网络和硬盘。

额外的数据为，传输一些必要的内容保证备份 VM 和主 VM 在执行非确定操作时是一致的。

为了检测主备 VM 是否失败，需要在相关服务器间保持心跳并监测 Logging Channel 的流量，并保证在失败时只有一个 VM 能够接替主 VM 的角色，尽管可能会出现脑裂的现象。

接下来介绍：

1. 主备如何保证同步，以及确定性的重放技术；
2. 描述 FT 协议的基本规则，保证主 VM 失效时没有数据丢失；
3. 描述以正确的方式检测和回应失效。

### 2.1 确定性重放实现

VM 的输入包括：

- 网络报文处理；
- 硬盘读取；
- 键盘鼠标输入。

`Non-deterministic events`: 虚中断；

`Non-deterministic operations`: 读取处理器的时钟周期。

不确定的因素导致虚拟机的冗余执行存在以下挑战：

1. 正确捕捉所有的输入以及不确定的因素，保证备份 VM 确定性执行；
2. 备份 VM 正确执行输入和 non-determinism；
3. 以不降低性能的方式执行；
4. 由于许多复杂的操作在 x86 处理器上都没有被定义，就会导致不确定性这一副作用。获取这些没有定义的副作用并重放它们也是难题。

#### VMWare deterministic replay

`VMWare deterministic replay` 为 vSphere 平台的 x86 VM 提供了功能。

Deterministic replay 记录了 VM 的输入、所有可能的 non-determinism 以及相关 log entries stream，记录到一个日志文件中。之后 VM 执行就会被正确重放。

- 对于 Non-deterministic operations：重要的信息将被记录，并允许操作被重新生成，造成相同的状态变化和输出；

- 对于 non-deterministic events，例如时钟/ IO 完成中断，事件发生时确切指令的位置也会被记录。在重放时，events 会被分发到指令流的相同位置。

  `VMWare deterministic replay`  对于 events 的记录和分发机制得益于 AMD 和 Intel 共同开发的硬件性能计数器。

`VMWare deterministic replay`  没有使用 `epoch`（批处理的概念），每个中断都会记录在它出现的地方并且高效地分发在合适的指令中。

### 2.2 FT Protocol

Log 不写盘，而是通过 logging channel 发送，备份 VM 实时重放日志项并和主 VM 执行相同的指令。然而，我们必须用严格的 FT protocol 扩增日志项，确保 FT。

#### 输出要求 Output Requirement

> 如果主 VM 挂掉，备份虚拟机将继续执行，并与主虚拟机向外部世界发送的所有输出保持一致。

由于在执行过程中存在 non-deterministic events ，主备的执行情况可能不同，只要在故障转移切换到备份 VM 期间，备 VM 能够满足输出要求，没有显式的状态和数据丢失，客户端就不会注意到服务中断或不一致性。

输出要求可以通过延迟所有外部输出（通常是网络包）来确保，直到备份虚拟机收到所有信息，使其能够重放执行，至少到该输出操作的点。

如果备 VM 在输出操作前的最后一条日志条目处上线，一些 non-deterministic events （例如传递给虚拟机的定时器中断）可能会在它执行输出操作之前改变其执行路径。


![FTVM-FTprotocol.png](https://cdn.hashnode.com/res/hashnode/image/upload/v1651656054664/l1aKStd15.png align="left")

#### 输出约束 Output Rule

> 主 VM 直到备 VM 接收并通告产生输出的 log entry 之后，再把输出发送给外界。



**为什么需要这一步**

类似于写的强一致性，必须要在主备都执行完成后返回。

（当备份 VM 还在执行上一个 log entry 时，由于主 VM 已经把输出返回给客户端，此时如果出现 failure，备立即变成主，会导致一些 non-deterministic events 和原来执行的不一致，导致不一致）

主在等待备 VM 执行 output operation 时不会阻塞，而是继续执行计算，不会显著地被 output delay 影响。

这样的约束能够保证主备状态一致。

不能保证在失败的情况下所有的输出都只被产生一次，因为当主发送输出时没有使用事务两段式提交。而网络设施能够处理丢包和重复包现象。

然而，传入的数据包可能会因为与服务器故障无关的任何原因而被丢弃，因此，网络基础设施、操作系统和应用程序的编写都是为了确保它们能够补偿丢失的数据包。

### 2.3 Detecting and Responding to Failure

#### Responding

1. 备 VM 失效

   主 VM *go live*：离开记录模式，停止向 logging channel 发送 logging entries，并正常执行程序。

2. 主 VM 失效

   备 VM 首先将 log entries 重放完成，然后停止 replaying 模式，正常执行程序。

   此时主备切换完成，由备 VM 向外部提供输出，此时需要设备相关的操作，允许输出能够发生：

   - 网络， VMware FT 将自动通告新的主 VM MAC 地址，物理节点将知道新的主 VM 在哪
   - 磁盘，需要重新定位 disk IOs（将在 3.4 节讨论）

#### Detecting

1. UDP heartbeating

   如果超时，就会触发失效；

2. logging traffic

   主要监测 logging message 和 ACK 是否规律。

可能会导致脑裂，因此需要保证只有一个主 VM 或备 VM 变为 live 模式，因此使用 shared storage 。当一个主/备 VM 尝试变为 live 模式时，**首先执行一个 shared storage 的原子 test-and-set 操作。**如果执行成功，则允许该 VM 变为 live 模式，如果操作失败，说明其他 VM 有变为 live 模式的，所以该 VM 直接 commit suicide。如果此 VM 无法接入 shared storage ，则等待 test-and-set 。

如果存储网络存在问题，VM 将不会执行任何工作。因此使用 shared storage 来解决脑裂问题将不会引入其他问题。

设计的最后一个方面是，一旦发生故障，其中一个虚拟机上线，VMware FT 就会通过在另一台主机上**启动一个新的备份虚拟机**来自动恢复冗余性。虽然这个过程在以前的大多数工作中没有涉及，但它是使容错虚拟机发挥作用的根本，需要仔细设计。

## 3. PRACTICAL IMPLEMENTATION OF FT

### 3.1 Starting And Restarting FT VMs

**与主虚拟机相同的状态下启动备份虚拟机的机制。**

这一机制也将在故障发生后重新启动备份虚拟机时使用。因此，该机制必须适用于处于任意状态（即不是刚刚启动）的运行中的主虚拟机。此外，我们希望该机制不会显着中断主 VM 的执行，因为这会影响 VM 的任何当前客户端。

**VMotion**：实现虚拟机热迁移

创建了一种修改过的 VMotion 形式，它可以在远程服务器上创建一个虚拟机的精确运行副本，但不会破坏本地服务器上的虚拟机。也就是说，我们修改后的 FT VMotion 将一个虚拟机克隆到远程主机上，而不是迁移它。FT VMotion 还设置了一个日志通道，并使源虚拟机作为主设备进入日志模式，而目标虚拟机作为新的备份进入重放模式。与正常的 VMotion 一样，FT VMotion 通常会中断主虚拟机的执行，时间不超过一秒钟。因此，在运行中的虚拟机上启用 FT 是一个简单、无干扰的操作。

启动备份虚拟机的另一个方面是选择一个服务器，在哪个服务器上运行。容错虚拟机在一个可以访问共享存储的服务器群中运行，因此所有虚拟机通常可以在群中的任何服务器上运行。这一灵活性允许 vSphere 在至少一个服务器失败时冗余存储 FT。

由 VMWare vSphere 实现一个云服务来维持管理和资源信息。当 failure 发生，主 VM 将立即通知集群服务建立新的备 VM。

效果：VMWare FT 能够在 failure 发生的几分钟内重新建立冗余 VM 而无需任何执行的终止。

### 3.2 Managing the Logging Channel

管理 Logging Channel 的流量。


![FTVM-LoggingBuffer.png](https://cdn.hashnode.com/res/hashnode/image/upload/v1651656065311/TyxiBfKLN.png align="left")

当备份 VM 的 log buffer 为空，直接暂停，直到有可用的 log entry。

当主 VM 的 log buffer 已满，需要停止执行，直到 log entries 被发送。停止执行会影响客户端，因此需要设计来最小化填充 log buffer 满的可能性。

1. 避免主 VM pause

   需要保证备份 VM 能够得到足够的资源（至少与主 VM 相当）

2. 避免 execution lag 太大

   不希望 execution lag 超过 1s。

   备 VM 活跃的时间大约等于故障被检测的时间 + 当前 execution lag 时间。

   **因此，我们有一个额外的机制来减缓主 VM 的速度，以防止备 VM 落后太远。**在我们发送和确认日志条目的协议中，我们发送了额外的信息，以确定主用和备用虚拟机之间的实时执行滞后。通常情况下，执行滞后小于 100 毫秒。如果备份虚拟机开始有明显的执行滞后（例如，超过1秒），VMware FT 开始放慢主虚拟机的速度，通知调度器给它少量的 CPU（最初只有百分之几）。我们使用一个缓慢的反馈回路，它将尝试逐步确定主虚拟机的适当 CPU 限制，使备份虚拟机能够匹配其执行。如果备份虚拟机继续落后，我们就继续逐步减少主虚拟机的 CPU 限制。反之，如果备份虚拟机赶上了，我们就逐渐增加主虚拟机的 CPU 限制，直到备份虚拟机恢复到稍小的 lag。

### 3.3 Operation on FT VMs

多种控制操作会应用到主 VM：

- 主 VM 被关机，备 VM 也会被关机，并且不会 go live；
- 任何主 VM 的资源管理都应该应用在备 VM；

对于这些操作，特殊控制项将会从主 VM 通过 logging channel 被发送到备 VM。

通常来说，大部分对 VM 的操作将只会在主 VM 初始化，然后 VMWare FT 发送必要的表项使备 VM 作出相应的变化。只有 VMotion 迁移指令能够独立在一个 VM 上完成。

主虚拟机的 VMotion 比普通的 VMotion 增加了一些复杂性，因为备份虚拟机必须从源主虚拟机断开连接，并在适当的时间重新连接到目标主虚拟机。备份虚拟机的VMotion有一个类似的问题，但增加了额外的复杂性。对于正常的 VMotion，我们要求在 VMotion 的最终切换发生时，所有未完成的磁盘IO都被 quiesced 静态化（即完成）。对于主 VM 来说，通过等待物理 IO 完成并将这些完成交付给虚拟机，这种静止是很容易处理的。但是，对于备 VM 来说，没有简单的方法可以使所有 IO 在任何需要的时间点上完成，因为备份虚拟机必须重放主虚拟机的执行，并在同一执行点上完成 IO。主 VM 可能正在运行一个工作负载，在正常执行期间总是有磁盘 IO 在传输。VMware FT 有一个独特的方法来解决这个问题：当一个备 VM 处于 VMotion 的最终切换点时，它通过 logging channel 请求主 VM 暂时停止其所有 IO 的运行。然后，备 VM 的 IO 在复制主 VM 执行静止 quiescing 操作时，也会在一个执行点被静止。

### 3.4 Implementation Issues for Disk IOs

1. 非阻塞式磁盘 IO 导致并行执行，在提升效率的同时会导致执行顺序的不确定性：
2. 使用 DMA 在 VM 的内存和磁盘之间传输，同时操作同一个页会导致不确定性；

Solution：检测磁盘 IO 冒险，并强制这些竞争串行执行。

磁盘操作和 VM 内的应用/系统内存接入存在冒险：

| Solution                                                     | Pros & Cons                                           |
| ------------------------------------------------------------ | ----------------------------------------------------- |
| 设置磁盘操作页面保护，当 VM 开始访问一个正在执行的磁盘操作页面时，陷入中断，等待磁盘操作完成后 VM 继续执行。 | 在 MMU 修改 page 的保护等级是很复杂的（因此没有采用） |
| [Bounce buffer](https://blog.csdn.net/force_eagle/article/details/7723772) <br />磁盘读时，先从磁盘读到 bounce buffer，然后读到 guest memory，IO 分发完成；<br />磁盘写时，先写到 bounce buffer，然后从 bounce buffer 写到 disk。 | 降低 disk operations，但是没有显著的性能下降          |

当主 VM 在 IO 没有返回结果的时候失败，备 VM 并不知道 IO 是否成功完成。此外，由于磁盘 IO 不是在备份虚拟机上从外部发出的，在新晋升的主虚拟机继续运行时，不会有明确的 IO 完成，这最终会导致虚拟机中的客户操作系统启动中止或重置程序。

我们可以发送**一个表示每个 IO 失败的错误**完成，因为即使 IO 成功完成，返回一个错误也是可以接受的。然而，客户操作系统可能对来自其本地磁盘的错误反应不大。相反，我们在备份虚拟机的上线过程中重新发出待定 IO 。因为我们已经消除了所有的 races，而且所有的 IO 都直接指定访问哪些内存和磁盘块，所以这些磁盘操作可以被重新发出，即使它们已经成功地完成了（也就是说，它们是空的）。

### 3.5 Implementation Issues for Network IOs

网络优化基于 hypervisor 异步更新虚拟机网络设备的状态。（例如 receive buffers 能够由正在执行的 VM 所在的 hypervisor 来更新）

除非能够保证所有的更新会在主和备的指令流的相同位置发生，否则备可能就和主状态不同。

对于 FT 的网络仿真码来说，最大的改变在于 disable 异步网络优化：

用传入的数据包异步更新虚拟机环形缓冲区的代码已被修改，以迫使客户向管理程序发出陷阱，在那里它可以记录更新，然后将其应用到虚拟机上。同样，对于 FT 来说，也不需要从传输队列中异步拉出数据包的代码，而是通过向管理程序发送陷阱来完成传输（下文指出的除外）。

消除网络设备的异步更新与第 2.2 节中描述的发送数据包的延迟相结合，为网络提供了一些性能挑战。我们采取了两种方法来提高运行 FT 的虚拟机网络性能。首先实现了集群优化，以减少虚拟机的陷阱和中断。当虚拟机以足够高的比特率传输数据时，管理程序可以对每组数据包进行一次传输陷阱，在最好的情况下，可以做到零陷阱，因为它可以将数据包作为接收新数据包的一部分来传输。同样，管理程序可以通过只发布一组数据包的中断来减少对虚拟机传入数据包的中断次数。

我们对网络的第二个性能优化是**减少传输数据包的延迟**。如前所述，管理程序必须延迟所有传输的数据包，直到它从备份中获得适当的日志条目的确认。减少传输延迟的关键是减少向备份发送日志信息并获得确认的时间。我们在这一领域的主要优化涉及确保发送和接收日志条目和确认都可以在没有任何线程上下文切换的情况下完成。VMware vSphere管理程序允许在TCP堆栈中注册一些功能，每当收到TCP数据时，这些功能就会从一个延迟执行的上下文（类似于Linux中的tasklet）中被调用。

在没有任何线程上下文切换的情况下，快速处理备上任何传入的日志消息和主虚拟机收到的任何确认。此外，当主虚拟机排队等待传输数据包时，我们通过调度一个延迟执行的上下文来强迫立即对相关的输出日志条目进行日志刷新。

## 4. DESIGN ALTERNATIVES

### 4.1 Shared vs Non-shared Disk

| Disk type       | Pros & Cons                                                  |
| --------------- | ------------------------------------------------------------ |
| Shared Disk     | 不需要推迟输出时间，因为只需要主 VM 进行磁盘读写，备 VM 不需要进行； |
| Non-shared Disk | 共享存储可能不能同时被主和备访问的情境下使用；<br />当 FT 可用时，两个 virtual disks 的副本必须以某种形式显式同步，以保证当备 VM 重启后，存储能够重新同步。<br />`FT VMotion` 不仅能够同步主备 VM，也能够同步 disk state。 |

### 4.2 Executing Disk Reads on the backup VM

在默认设计中，无论是否是共享存储，备 VM 都不需要读取 virtual disk。因为读可以被看作是一种输入，主 VM 能够通过 logging channel 将结果发给备 VM。

另一种设计是让备 VM 执行磁盘读取，从而消除对磁盘读取数据的 logging。这种方法可以大大减少做大量磁盘读取的工作负载的日志通道的流量。然而，它可能会减慢备份虚拟机的执行速度，因为备份虚拟机必须执行所有的磁盘读取，如果这些读取在到达虚拟机执行过程中在主 VM 上完成时还没有实际完成，就必须等待。

另外，必须做一些额外的工作来处理失败的磁盘读取操作。如果主磁盘读取成功，但备相应磁盘读取失败，那么备磁盘读取必须重试直到成功，因为备必须在内存中获得与主磁盘相同的数据。相反，如果主磁盘读取失败，那么目标内存的内容必须通过日志通道发送给备份，因为内存的内容将是不确定的，不一定被备 VM 成功的磁盘读取所复制。

最后，如果这种磁盘读取方式与共享磁盘配置一起使用，还有一个微妙的问题。如果主 VM 对某一特定磁盘位置进行读取，然后很快对同一磁盘位置进行写入，那么磁盘写入必须延迟到备 VM 执行了第一次磁盘读取。这种依赖性可以被正确检测和处理，但会给实现增加额外的复杂性。